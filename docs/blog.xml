<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Hannah Lyons</title>
<link>https://hannahl8.github.io/blog.html</link>
<atom:link href="https://hannahl8.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Hannah Lyons Personal Blog</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Sun, 05 Nov 2023 04:00:00 GMT</lastBuildDate>
<item>
  <title>Anomaly/Outlier Detection</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/anomaly/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Anomaly detection, a critical aspect of machine learning, involves identifying patterns in data that deviate significantly from the norm. This technique finds applications in various domains, from fraud detection in financial transactions to detecting anomalies in network traffic for cybersecurity.</p>
</section>
<section id="challenges-of-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="challenges-of-anomaly-detection">Challenges of Anomaly Detection</h2>
<p>While anomaly detection is a powerful tool, it comes with challenges. Real-world data often exhibits diverse distributions, and datasets can be imbalanced, making it tricky to identify rare anomalies accurately. Robust algorithms are essential to overcome these challenges.</p>
</section>
<section id="dbscan-for-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-for-anomaly-detection"><strong>DBSCAN for Anomaly Detection</strong></h2>
<p>Density-Based Spatial Clustering of Applications with Noise (DBSCAN) emerges as a robust algorithm for anomaly detection. Unlike traditional methods, DBSCAN doesn’t assume a specific shape for clusters and can effectively isolate points in low-density regions as outliers.</p>
<p>Let’s implement anomaly detection using DBSCAN in Python:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DBSCAN</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_blobs</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to generate a synthetic dataset with outliers</span></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> generate_dataset_with_outliers(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>):</span>
<span id="cb1-8">    np.random.seed(seed)</span>
<span id="cb1-9">    X, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_blobs(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, cluster_std<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-10">    outliers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(low<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, high<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.concatenate([X, outliers]), np.concatenate([np.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>), np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)])</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to visualize anomalies with DBSCAN labels</span></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_anomalies(X, labels, title):</span>
<span id="cb1-15">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-16">    plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb1-17">    plt.title(title)</span>
<span id="cb1-18">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 1'</span>)</span>
<span id="cb1-19">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 2'</span>)</span>
<span id="cb1-20">    plt.show()</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1: Generate a synthetic dataset with outliers</span></span>
<span id="cb1-23">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_dataset_with_outliers()</span>
<span id="cb1-24"></span>
<span id="cb1-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2: Train a DBSCAN model for anomaly detection</span></span>
<span id="cb1-26">dbscan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DBSCAN(eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, min_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb1-27">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dbscan.fit_predict(X)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 3: Visualize anomalies with DBSCAN labels</span></span>
<span id="cb1-30">plot_anomalies(X, labels, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly Detection with DBSCAN'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/anomaly/index_files/figure-html/cell-2-output-1.png" width="682" height="523"></p>
</div>
</div>
<p>Visualizing anomalies is crucial for interpreting model results. Scatter plots with DBSCAN labels provide an intuitive representation of the identified anomalies in the dataset.</p>
</section>
<section id="evaluation-metrics-for-anomaly-detection" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metrics-for-anomaly-detection"><strong>Evaluation Metrics for Anomaly Detection</strong></h2>
<p>Evaluating anomaly detection models poses challenges due to the scarcity of anomalies. Metrics such as precision, recall, and F1 score provide a nuanced understanding of the model’s performance.</p>
<p>Let’s calculate precision, recall, and F1 score for anomaly detection results:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> precision_score, recall_score, f1_score</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DBSCAN</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_blobs</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to generate a synthetic dataset with outliers</span></span>
<span id="cb2-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> generate_dataset_with_outliers(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>):</span>
<span id="cb2-9">    np.random.seed(seed)</span>
<span id="cb2-10">    X, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_blobs(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, cluster_std<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb2-11">    outliers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(low<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, high<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb2-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.concatenate([X, outliers]), np.concatenate([np.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)])</span>
<span id="cb2-13"></span>
<span id="cb2-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to visualize anomalies with DBSCAN labels</span></span>
<span id="cb2-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_anomalies(X, labels, title):</span>
<span id="cb2-16">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb2-17">    plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb2-18">    plt.title(title)</span>
<span id="cb2-19">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 1'</span>)</span>
<span id="cb2-20">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 2'</span>)</span>
<span id="cb2-21">    plt.show()</span>
<span id="cb2-22"></span>
<span id="cb2-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1: Generate a synthetic dataset with outliers</span></span>
<span id="cb2-24">X, y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_dataset_with_outliers()</span>
<span id="cb2-25"></span>
<span id="cb2-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2: Train a DBSCAN model for anomaly detection</span></span>
<span id="cb2-27">dbscan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DBSCAN(eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, min_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb2-28">predicted_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dbscan.fit_predict(X)</span>
<span id="cb2-29"></span>
<span id="cb2-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 3: Visualize anomalies with DBSCAN labels</span></span>
<span id="cb2-31">plot_anomalies(X, predicted_labels, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Anomaly Detection with DBSCAN'</span>)</span>
<span id="cb2-32"></span>
<span id="cb2-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 4: Evaluate the model using precision, recall, and F1 score</span></span>
<span id="cb2-34">precision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_score(y_true, predicted_labels, pos_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-35">recall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall_score(y_true, predicted_labels, pos_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-36">f1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> f1_score(y_true, predicted_labels, pos_label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-37"></span>
<span id="cb2-38"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Precision: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>precision<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-39"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Recall: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>recall<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-40"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"F1 Score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/anomaly/index_files/figure-html/cell-3-output-1.png" width="682" height="523"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Precision: 1.00
Recall: 0.90
F1 Score: 0.95</code></pre>
</div>
</div>
<p>Anomaly detection, powered by algorithms like DBSCAN, plays a vital role in uncovering irregularities in data. The combination of effective visualizations and evaluation metrics enables us to gain insights into the anomalies present, providing a foundation for critical decision-making in various domains.</p>


</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/anomaly/index.html</guid>
  <pubDate>Sun, 05 Nov 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Classification</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/classification/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Classification, a cornerstone of machine learning, empowers systems to make informed decisions based on input features. From determining whether an email is spam to diagnosing diseases, classification algorithms play a pivotal role in automating decision-making processes.</p>
</section>
<section id="types-of-classification-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="types-of-classification-algorithms">Types of Classification Algorithms</h2>
<p>There are several classification algorithms, each suited to different types of problems:</p>
<ul>
<li><p><strong>Logistic Regression:</strong> Ideal for binary classification tasks.</p></li>
<li><p><strong>Decision Trees:</strong> Effective for both binary and multiclass classification.</p></li>
<li><p><strong>Support Vector Machines (SVM):</strong> Robust for linear and nonlinear classification.</p></li>
</ul>
<p>Let’s implement a simple classification model using logistic regression in Python:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_curve, roc_auc_score, precision_recall_curve</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic classification data</span></span>
<span id="cb1-8">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-9">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-10">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>).astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>).flatten()</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split the data into training and testing sets</span></span>
<span id="cb1-13">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train a logistic regression model</span></span>
<span id="cb1-16">logreg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression()</span>
<span id="cb1-17">logreg.fit(X_train, y_train)</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict probabilities on the test set</span></span>
<span id="cb1-20">y_proba <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logreg.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
</div>
</section>
<section id="receiver-operating-characteristic-roc-curve" class="level2">
<h2 class="anchored" data-anchor-id="receiver-operating-characteristic-roc-curve"><strong>Receiver Operating Characteristic (ROC) Curve</strong></h2>
<p>ROC curves visualize the trade-off between true positive rate (sensitivity) and false positive rate. The area under the ROC curve (AUC-ROC) is a valuable metric for model performance.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the ROC curve</span></span>
<span id="cb2-2">fpr, tpr, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_curve(y_test, y_proba)</span>
<span id="cb2-3">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb2-4">plt.plot(fpr, tpr, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'darkorange'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ROC curve'</span>)</span>
<span id="cb2-5">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'navy'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Random Guess'</span>)</span>
<span id="cb2-6">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive Rate'</span>)</span>
<span id="cb2-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Positive Rate'</span>)</span>
<span id="cb2-8">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Receiver Operating Characteristic (ROC) Curve'</span>)</span>
<span id="cb2-9">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lower right'</span>)</span>
<span id="cb2-10">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/classification/index_files/figure-html/cell-3-output-1.png" width="663" height="523"></p>
</div>
</div>
</section>
<section id="precision-recall-pr-curve" class="level2">
<h2 class="anchored" data-anchor-id="precision-recall-pr-curve"><strong>Precision-Recall (PR) Curve</strong></h2>
<p>PR curves focus on the trade-off between precision and recall, particularly valuable in imbalanced datasets.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the Precision-Recall curve</span></span>
<span id="cb3-2">precision, recall, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_recall_curve(y_test, y_proba)</span>
<span id="cb3-3">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb3-4">plt.plot(recall, precision, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision-Recall curve'</span>)</span>
<span id="cb3-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Recall (Sensitivity)'</span>)</span>
<span id="cb3-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision'</span>)</span>
<span id="cb3-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision-Recall Curve'</span>)</span>
<span id="cb3-8">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lower left'</span>)</span>
<span id="cb3-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/classification/index_files/figure-html/cell-4-output-1.png" width="663" height="523"></p>
</div>
</div>
</section>
<section id="confusion-matrix" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrix"><strong>Confusion Matrix</strong></h2>
<p>The confusion matrix provides a detailed understanding of a classification model’s performance, breaking down predictions into true positives, true negatives, false positives, and false negatives.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> confusion_matrix</span>
<span id="cb4-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb4-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming logreg, X_test, and y_test are defined as in the previous code</span></span>
<span id="cb4-8"></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate predictions</span></span>
<span id="cb4-10">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logreg.predict(X_test)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate confusion matrix</span></span>
<span id="cb4-13">cm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the confusion matrix using matplotlib</span></span>
<span id="cb4-16">plt.imshow(cm, interpolation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nearest'</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.Blues)</span>
<span id="cb4-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Confusion Matrix'</span>)</span>
<span id="cb4-18">plt.colorbar()</span>
<span id="cb4-19"></span>
<span id="cb4-20">classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 0'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 1'</span>]</span>
<span id="cb4-21">tick_marks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(classes))</span>
<span id="cb4-22">plt.xticks(tick_marks, classes, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>)</span>
<span id="cb4-23">plt.yticks(tick_marks, classes)</span>
<span id="cb4-24"></span>
<span id="cb4-25">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted label'</span>)</span>
<span id="cb4-26">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True label'</span>)</span>
<span id="cb4-27"></span>
<span id="cb4-28">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/classification/index_files/figure-html/cell-5-output-1.png" width="535" height="479"></p>
</div>
</div>
<p>In conclusion, classification in machine learning is a powerful tool for automating decision-making processes. By implementing and evaluating classification models, we gain insights into their performance through metrics like ROC curves, PR curves, and confusion matrices. These visualizations provide a nuanced understanding of a model’s strengths and weaknesses, facilitating informed decision-making in real-world applications.</p>


</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/classification/index.html</guid>
  <pubDate>Fri, 20 Oct 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Linear and Nonlinear Regression</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/regression/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Regression, a fundamental concept in machine learning, enables us to model relationships between variables. Whether predicting house prices based on square footage or analyzing the impact of advertising spend on sales, regression plays a pivotal role in understanding and predicting patterns in data.</p>
</section>
<section id="linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression"><strong>Linear Regression</strong></h2>
<p>Linear regression is a straightforward method for modeling linear relationships between variables. In a simple linear regression model, the relationship is expressed as <img src="https://latex.codecogs.com/png.latex?y=mx+b"> where <img src="https://latex.codecogs.com/png.latex?y"> is the target variable, <img src="https://latex.codecogs.com/png.latex?x"> is the feature, <img src="https://latex.codecogs.com/png.latex?m"> is the slope, and <img src="https://latex.codecogs.com/png.latex?b"> is the intercept. For multiple features, the equation becomes a linear combination.</p>
<p>Linear regression can be implemented effortlessly using Python’s scikit-learn library. Let’s generate a synthetic dataset and visualize the linear regression line:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic linear data</span></span>
<span id="cb1-6">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-7">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-8">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train linear regression model</span></span>
<span id="cb1-11">linear_reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb1-12">linear_reg.fit(X, y)</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the linear regression line</span></span>
<span id="cb1-15">plt.scatter(X, y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>)</span>
<span id="cb1-16">plt.plot(X, linear_reg.predict(X), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Regression'</span>)</span>
<span id="cb1-18">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature'</span>)</span>
<span id="cb1-19">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>)</span>
<span id="cb1-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/regression/index_files/figure-html/cell-2-output-1.png" width="585" height="449"></p>
</div>
</div>
</section>
<section id="nonlinear-regression" class="level2">
<h2 class="anchored" data-anchor-id="nonlinear-regression"><strong>Nonlinear Regression</strong></h2>
<p>While linear regression is powerful, not all relationships are linear. Nonlinear regression extends the concept by accommodating more complex patterns. Polynomial regression is a common technique, where the relationship between variables is expressed as a polynomial equation.</p>
<p>Let’s use Python to implement nonlinear regression through polynomial regression. This time, we’ll generate a synthetic dataset with a nonlinear relationship:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PolynomialFeatures</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.pipeline <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_pipeline</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic nonlinear data</span></span>
<span id="cb2-8">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-9">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb2-10">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train nonlinear regression model (polynomial regression)</span></span>
<span id="cb2-13">degree <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb2-14">poly_reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_pipeline(PolynomialFeatures(degree), LinearRegression())</span>
<span id="cb2-15">poly_reg.fit(X, y)</span>
<span id="cb2-16"></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the nonlinear regression curve</span></span>
<span id="cb2-18">X_range <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-19">plt.scatter(X, y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>)</span>
<span id="cb2-20">plt.plot(X_range, poly_reg.predict(X_range), color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-21">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Nonlinear Regression (Polynomial)'</span>)</span>
<span id="cb2-22">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature'</span>)</span>
<span id="cb2-23">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>)</span>
<span id="cb2-24">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/regression/index_files/figure-html/cell-3-output-1.png" width="585" height="449"></p>
</div>
</div>
<p>The power of regression becomes evident when we visualize the results. Scatter plots with regression lines or curves help us understand how well the model captures the underlying patterns in the data.</p>
<p>In conclusion, linear and nonlinear regression are indispensable tools in the machine learning toolbox. While linear regression is effective for simple relationships, nonlinear regression allows us to model more complex patterns. The ability to implement these techniques with Python makes them accessible and applicable to a wide range of real-world scenarios.</p>


</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/regression/index.html</guid>
  <pubDate>Thu, 05 Oct 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Clustering</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/clustering/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Clustering, a fundamental technique in machine learning, is the process of grouping similar data points together. Its applications are diverse, ranging from customer segmentation in marketing to anomaly detection in cybersecurity. By identifying patterns within datasets, clustering enables us to gain valuable insights and make informed decisions.</p>
</section>
<section id="types-of-clustering-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="types-of-clustering-algorithms"><strong>Types of Clustering Algorithms</strong></h2>
<p>Clustering algorithms come in various flavors, each with its unique approach to grouping data:</p>
<ul>
<li><p><strong>K-Means:</strong> Divides data into k clusters, where each cluster is represented by its centroid.</p></li>
<li><p><strong>Hierarchical Clustering:</strong> Forms a tree of clusters, allowing for hierarchical organization.</p></li>
<li><p><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise):</strong> A density-based algorithm that identifies clusters based on the density of data points.</p></li>
</ul>
</section>
<section id="dbscan-a-density-based-approach" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-a-density-based-approach"><strong>DBSCAN: A Density-Based Approach:</strong></h2>
<p>DBSCAN stands out for its ability to discover clusters of arbitrary shapes. The algorithm works by identifying core points, which are densely packed, and expanding clusters by connecting core points. It also identifies noise points that do not belong to any cluster.</p>
</section>
<section id="dbscan-in-action" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-in-action"><strong>DBSCAN in Action</strong></h2>
<p>Let’s demonstrate the power of DBSCAN using Python and scikit-learn. We’ll start by generating a synthetic dataset:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DBSCAN</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_blobs</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a synthetic dataset</span></span>
<span id="cb1-7">X, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_blobs(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, cluster_std<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.60</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply DBSCAN</span></span>
<span id="cb1-10">dbscan <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DBSCAN(eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, min_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb1-11">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dbscan.fit_predict(X)</span></code></pre></div>
</div>
</section>
<section id="data-visualization-with-scatter-plots" class="level2">
<h2 class="anchored" data-anchor-id="data-visualization-with-scatter-plots"><strong>Data Visualization with Scatter Plots</strong></h2>
<p>Visualizing the results of clustering is crucial for understanding the underlying structure of the data. Let’s create a scatter plot that represents the original data points with cluster labels:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the clusters</span></span>
<span id="cb2-2">plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>labels, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb2-3">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'DBSCAN Clustering'</span>)</span>
<span id="cb2-4">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 1'</span>)</span>
<span id="cb2-5">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 2'</span>)</span>
<span id="cb2-6">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/clustering/index_files/figure-html/cell-3-output-1.png" width="576" height="449"></p>
</div>
</div>
<p>Clustering, especially with the powerful DBSCAN algorithm, opens new avenues for extracting patterns from data. As we’ve seen, DBSCAN’s ability to identify clusters based on density makes it versatile for a wide range of applications. By visualizing the results, we gain a deeper understanding of the data’s inherent structure, providing a solid foundation for subsequent analysis and decision-making.</p>


</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/clustering/index.html</guid>
  <pubDate>Wed, 20 Sep 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Probability Theory and Random Variables</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/probability/index.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the realm of machine learning, uncertainty is inherent. Models make predictions based on patterns learned from data, and probability theory provides a formal framework for dealing with uncertainty. Random variables are employed to represent uncertain quantities, making probability theory a cornerstone for building and interpreting machine learning models.</p>
<p>Machine learning algorithms often assume specific probability distributions. For instance:</p>
<ul>
<li><p>The normal distribution is frequently assumed in linear regression and Gaussian processes.</p></li>
<li><p>The binomial distribution is relevant for problems involving binary outcomes, such as classification tasks.</p></li>
</ul>
<p>Understanding the characteristics of these distributions is vital when selecting appropriate models and interpreting results.</p>
<p>Random variables represent various aspects of data. Features can be modeled as random variables, and understanding their distribution is crucial for feature engineering. Additionally, the uncertainty associated with predictions is often expressed through probability distributions, making random variables central to the prediction process.</p>
</section>
<section id="data-visualization" class="level2">
<h2 class="anchored" data-anchor-id="data-visualization">Data Visualization</h2>
<p>Let’s use Python and Matplotlib to create a histogram of a simulated random variable:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a random dataset</span></span>
<span id="cb1-5">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-6">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define specific colors (same as css from quarto vapor theme)</span></span>
<span id="cb1-9">webpage_background_color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#1a0933'</span></span>
<span id="cb1-10">pink <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#ea39b8'</span></span>
<span id="cb1-11">purple <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#6f42c1'</span></span>
<span id="cb1-12">blue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#32fbe2'</span></span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a histogram</span></span>
<span id="cb1-15">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb1-16">hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.hist(data, bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>purple, ec<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb1-17">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Histogram of Random Variable'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>purple)</span>
<span id="cb1-18">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Values'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb1-19">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Frequency'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb1-20">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-21">ax.tick_params(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>, colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb1-22">ax.tick_params(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb1-23"></span>
<span id="cb1-24">ax.set_facecolor(pink)</span>
<span id="cb1-25">fig.set_facecolor(webpage_background_color)</span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the plot</span></span>
<span id="cb1-28">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/probability/index_files/figure-html/cell-2-output-1.png" width="593" height="449"></p>
</div>
</div>
<p>Probability theory and random variables are not just theoretical concepts; they are integral to the practical application of machine learning. Models are built upon the assumptions of probability distributions, and the visualization of data through histograms aids in model interpretation and validation. As you dive deeper into machine learning, a solid understanding of these foundational concepts will empower you to make more informed decisions in model selection, training, and evaluation.</p>
<p>The following code generates a dataset with two classes, trains a Random Forest Classifier on the data, and then generates predictions on a test set. The histograms before and after applying the machine learning model are plotted above one another for comparison.</p>
<p>The <strong><code>generate_dataset</code></strong> function creates a synthetic dataset with two classes, and the <strong><code>plot_histograms</code></strong> function is used to visualize the distribution before and after applying the machine learning model. The accuracy of the model is also printed to give an idea of its performance.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to generate a random dataset with two classes</span></span>
<span id="cb2-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> generate_dataset(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>):</span>
<span id="cb2-7">    np.random.seed(seed)</span>
<span id="cb2-8">    class1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>)</span>
<span id="cb2-9">    class2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>)</span>
<span id="cb2-10">    labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span></span>
<span id="cb2-11">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([class1, class2])</span>
<span id="cb2-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> data, labels</span>
<span id="cb2-13"></span>
<span id="cb2-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to plot histograms</span></span>
<span id="cb2-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_histograms(data, title):</span>
<span id="cb2-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a histogram</span></span>
<span id="cb2-17">    fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb2-18">    hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.hist(data, bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>purple, ec<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb2-19">    ax.set_title(title, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>purple)</span>
<span id="cb2-20">    ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Values'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb2-21">    ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Frequency'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb2-22">    ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb2-23">    ax.tick_params(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>, colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb2-24">    ax.tick_params(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>blue)</span>
<span id="cb2-25">    </span>
<span id="cb2-26">    ax.set_facecolor(pink)</span>
<span id="cb2-27">    fig.set_facecolor(webpage_background_color)</span>
<span id="cb2-28">    </span>
<span id="cb2-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Show the plot</span></span>
<span id="cb2-30">    plt.show()</span>
<span id="cb2-31"></span>
<span id="cb2-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1: Generate a random dataset</span></span>
<span id="cb2-33">data_before, labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_dataset()</span>
<span id="cb2-34"></span>
<span id="cb2-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2: Split the data into training and testing sets</span></span>
<span id="cb2-36">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(data_before.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), labels, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-37"></span>
<span id="cb2-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 3: Train a Random Forest Classifier</span></span>
<span id="cb2-39">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-40">clf.fit(X_train, y_train)</span>
<span id="cb2-41"></span>
<span id="cb2-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 4: Make predictions on the test set</span></span>
<span id="cb2-43">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb2-44"></span>
<span id="cb2-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 5: Assess accuracy</span></span>
<span id="cb2-46">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, predictions)</span>
<span id="cb2-47"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Accuracy of the model: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2%}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-48"></span>
<span id="cb2-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 6: Generate a dataset after applying the machine learning model</span></span>
<span id="cb2-50">data_after <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]])</span>
<span id="cb2-51"></span>
<span id="cb2-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 7: Plot histograms to compare before and after</span></span>
<span id="cb2-53">plot_histograms(data_before, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Dataset'</span>)</span>
<span id="cb2-54">plot_histograms(data_after, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dataset after Machine Learning'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy of the model: 89.00%</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/probability/index_files/figure-html/cell-3-output-2.png" width="585" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/probability/index_files/figure-html/cell-3-output-3.png" width="593" height="449"></p>
</div>
</div>


</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/probability/index.html</guid>
  <pubDate>Tue, 05 Sep 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Tetris and Machine Learning</title>
  <dc:creator>Hannah Lyons</dc:creator>
  <link>https://hannahl8.github.io/posts/machine-learning-intro/intro-to-ml/index.html</link>
  <description><![CDATA[ 




<section id="tetris" class="level1">
<h1>Tetris</h1>
<p>Little did I know, Tetris, the classic video game, can be related to machine learning and data analytics in various ways.</p>
<p>I am a huge fan of the game, and I am obsessed with a newer version that facilitates multi-player options; Tetris® Effect: Connected.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hannahl8.github.io/posts/machine-learning-intro/intro-to-ml/teriseffect.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p>I decided to stream on twitch a few times… that didn’t go anywhere. There are several other players that I’ve seen stream online, like doremypuyotet, who is a Tetris expert; the video below is them playing.</p>
<p>[](<iframe width="640" height="360" src="https://www.youtube.com/embed/z3aXzz2Ux84" title="[Tetris Effect: Connected] Zone Battle: Doremy vs. uyeshota (07-02-2021, PC)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>)</p>
<p>As you can see doremypuyotet has incredible technique and it is absolutely mind blowing watching them play the game.</p>
<p>I wondered though, how would an Artificial Tetris Agent perform at a game of zone battle against someone like doremypuyotet? The agent would have to take several more aspects into consideration than it does in the classic video game. The dynamics of player interactions, adaptive game play, and the wealth of data generated present opportunities to enhance the gaming experience through data-driven insights and algorithmic optimization’s.</p>
<section id="tetris-applications-to-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="tetris-applications-to-machine-learning">Tetris Applications to Machine Learning</h2>
<section id="optimization-and-heuristics" class="level4">
<h4 class="anchored" data-anchor-id="optimization-and-heuristics">Optimization and Heuristics</h4>
<p>Algorithmic Efficiency: Tetris involves optimizing the placement of falling blocks to complete lines. This is analogous to optimization problems in machine learning where algorithms seek to minimize or maximize a certain objective function.</p>
<p>Heuristics: Players often develop heuristics or rules of thumb to make decisions quickly. Similarly, in machine learning, heuristics can be used to guide algorithms toward solutions without exhaustive search.</p>
</section>
<section id="reinforcement-learning" class="level4">
<h4 class="anchored" data-anchor-id="reinforcement-learning">Reinforcement Learning</h4>
<p>Learning from Experience: Reinforcement learning involves agents learning by interacting with an environment and receiving feedback in the form of rewards or penalties. In Tetris, players learn from the consequences of their moves, much like reinforcement learning algorithms learn from trial and error.</p>
</section>
<section id="pattern-recognition" class="level4">
<h4 class="anchored" data-anchor-id="pattern-recognition">Pattern Recognition</h4>
<p>Feature Extraction: In Tetris, players recognize patterns in the falling blocks to make decisions. In data analytics, feature extraction involves recognizing patterns in data to enhance the performance of algorithms.</p>
<p>Image Recognition: Tetris can be framed as an image recognition problem where the goal is to identify patterns in the arrangement of blocks. Image recognition is a common application in machine learning.</p>
</section>
<section id="predictive-analytics" class="level4">
<h4 class="anchored" data-anchor-id="predictive-analytics">Predictive Analytics</h4>
<p>Anticipating Future States: In Tetris, players need to anticipate the future states of the game based on the current configuration of blocks. Predictive analytics in machine learning involves forecasting future trends or outcomes based on historical data.</p>
</section>
<section id="data-driven-decision-making" class="level4">
<h4 class="anchored" data-anchor-id="data-driven-decision-making">Data-driven Decision Making</h4>
<p>Real-time Decision Making: Tetris requires quick decision-making based on the constantly changing game state. In a similar vein, real-time data analytics involves making decisions based on rapidly changing data streams.</p>
</section>
<section id="data-visualization" class="level4">
<h4 class="anchored" data-anchor-id="data-visualization">Data Visualization</h4>
<p>Spatial Visualization: Tetris involves visualizing the spatial arrangement of blocks. Data visualization is a crucial aspect of data analytics, helping individuals understand complex patterns and trends in data through graphical representations.</p>
</section>
<section id="evolutionary-algorithms" class="level4">
<h4 class="anchored" data-anchor-id="evolutionary-algorithms">Evolutionary Algorithms</h4>
<p>Genetic Algorithms: Tetris can be approached as a problem of evolving a strategy over time. Genetic algorithms, a type of evolutionary algorithm, involve evolving solutions to problems through processes inspired by natural selection.</p>
</section>
<section id="algorithmic-complexity" class="level4">
<h4 class="anchored" data-anchor-id="algorithmic-complexity">Algorithmic Complexity</h4>
<p>Complexity Analysis: Analyzing the complexity of Tetris strategies can be similar to analyzing the time and space complexity of algorithms in machine learning. Understanding the efficiency and scalability of algorithms is essential in both contexts.</p>
</section>
<section id="big-data" class="level4">
<h4 class="anchored" data-anchor-id="big-data">Big Data</h4>
<p>Managing Information Overload: Tetris speeds up as the game progresses, leading to an increasing amount of information to process. Dealing with information overload is a challenge in both Tetris and big data analytics.</p>
</section>
<section id="competition-and-strategy" class="level4">
<h4 class="anchored" data-anchor-id="competition-and-strategy">Competition and Strategy</h4>
<p>Game Theory: Tetris can be viewed through the lens of game theory, where players make strategic decisions to maximize their score. Game theory concepts are also applicable in various areas of machine learning, such as in competitive scenarios.</p>


</section>
</section>
</section>

 ]]></description>
  <category>code</category>
  <guid>https://hannahl8.github.io/posts/machine-learning-intro/intro-to-ml/index.html</guid>
  <pubDate>Fri, 01 Sep 2023 04:00:00 GMT</pubDate>
</item>
</channel>
</rss>
