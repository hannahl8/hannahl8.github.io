{
  "hash": "80af7915bdf0a947fc5c295386b93985",
  "result": {
    "markdown": "---\ntitle: 'Linear and Nonlinear Regression'\ndate: '2023-10-20'\ncategories: ['code']\ndescription: 'Navigating Trends with Linear and Nonlinear Regression in Machine Learning'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n## Introduction\n\nRegression, a fundamental concept in machine learning, enables us to model relationships between variables. Whether predicting house prices based on square footage or analyzing the impact of advertising spend on sales, regression plays a pivotal role in understanding and predicting patterns in data.\n\n## Data Visualization\n\nI use the following colors in all of my blogs data visualizations\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Define specific colors (same as CSS from quarto vapor theme)\nbackground = '#1b133a'\npink = '#ea39b8'\npurple = '#6f42c1'\nblue = '#32fbe2'\n```\n:::\n\n\nI will use the following **`plot_scatter`** function to create the data visualizations on this page\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\ndef plot_scatter(X, X_Range, ax_plot, title):\n  fig, ax = plt.subplots()\n  scatter = ax.scatter(X, y, color=blue, edgecolor='black', alpha=0.6)\n  ax.plot(X_Range, ax_plot, color=purple, linewidth=2)\n  ax.set_title(title, color=purple)\n  ax.set_xlabel('Feature', color=blue)\n  ax.set_ylabel('Target', color=blue)\n  ax.grid(True, linestyle='--', alpha=0.5)\n  ax.tick_params(axis='x', colors=blue)\n  ax.tick_params(axis='y', colors=blue)\n  ax.set_facecolor(pink)\n  fig.set_facecolor(background)\n  plt.show()\n```\n:::\n\n\n### **Linear Regression**\n\nLinear regression is a straightforward method for modeling linear relationships between variables. In a simple linear regression model, the relationship is expressed as $y=mx+b$ where $y$ is the target variable, $x$ is the feature, $m$ is the slope, and $b$ is the intercept. For multiple features, the equation becomes a linear combination.\n\nLinear regression can be implemented effortlessly using Python's scikit-learn library. Let's generate a synthetic dataset and visualize the linear regression line:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic linear data\nnp.random.seed(42)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Train linear regression model\nlinear_reg = LinearRegression()\nlinear_reg.fit(X, y)\n\n# Visualize the linear regression line\nax_plot = linear_reg.predict(X)\nplot_scatter(X, X, ax_plot, 'Linear Regression')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=585 height=449}\n:::\n:::\n\n\n### **Nonlinear Regression**\n\nWhile linear regression is powerful, not all relationships are linear. Nonlinear regression extends the concept by accommodating more complex patterns. Polynomial regression is a common technique, where the relationship between variables is expressed as a polynomial equation.\n\nLet's use Python to implement nonlinear regression through polynomial regression. This time, we'll generate a synthetic dataset with a nonlinear relationship:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n\n# Generate synthetic nonlinear data\nnp.random.seed(42)\nX = 6 * np.random.rand(100, 1) - 3\ny = 0.5 * X**2 + X + 2 + np.random.randn(100, 1)\n\n# Train nonlinear regression model (polynomial regression)\ndegree = 2\npoly_reg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\npoly_reg.fit(X, y)\n\n# Visualize the nonlinear regression curve\nX_range = np.linspace(-3, 3, 100).reshape(-1, 1)\nax_plot =  poly_reg.predict(X_range)\nplot_scatter(X, X_range, ax_plot, 'Nonlinear Regression (Polynomial)')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=585 height=449}\n:::\n:::\n\n\nThe power of regression becomes evident when we visualize the results. Scatter plots with regression lines or curves help us understand how well the model captures the underlying patterns in the data.\n\nIn conclusion, linear and nonlinear regression are indispensable tools in the machine learning toolbox. While linear regression is effective for simple relationships, nonlinear regression allows us to model more complex patterns. The ability to implement these techniques with Python makes them accessible and applicable to a wide range of real-world scenarios.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}