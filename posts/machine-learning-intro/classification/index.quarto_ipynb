{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Classification'\n",
        "date: '2023-10-30'\n",
        "categories: ['Code', 'Academic']\n",
        "description: 'ROC, PR, Confusion Matrix'\n",
        "execute: \n",
        "  message: false\n",
        "  warning: false\n",
        "editor_options: \n",
        "  chunk_output_type: console\n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Classification, a cornerstone of machine learning, empowers systems to make informed decisions based on input features. From determining whether an email is spam to diagnosing diseases, classification algorithms play a pivotal role in automating decision-making processes.\n",
        "\n",
        "### Types of Classification Algorithms\n",
        "\n",
        "There are several classification algorithms, each suited to different types of problems:\n",
        "\n",
        "-   **Logistic Regression:** Ideal for binary classification tasks.\n",
        "\n",
        "-   **Decision Trees:** Effective for both binary and multiclass classification.\n",
        "\n",
        "-   **Support Vector Machines (SVM):** Robust for linear and nonlinear classification.\n",
        "\n",
        "Let's implement a simple classification model using logistic regression in Python:\n"
      ],
      "id": "96954851"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
        "\n",
        "# Generate synthetic classification data\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1)\n",
        "y = (X > 0.5).astype(int).flatten()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_proba = logreg.predict_proba(X_test)[:, 1]"
      ],
      "id": "e6399e87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualization\n",
        "\n",
        "I use the following colors in all of my blogs data visualizations\n"
      ],
      "id": "1c06d214"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define specific colors (same as CSS from quarto vapor theme)\n",
        "background = '#1b133a'\n",
        "pink = '#ea39b8'\n",
        "purple = '#6f42c1'\n",
        "blue = '#32fbe2'"
      ],
      "id": "6855eec8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Receiver Operating Characteristic (ROC) Curve**\n",
        "\n",
        "ROC curves visualize the trade-off between true positive rate (sensitivity) and false positive rate. The area under the ROC curve (AUC-ROC) is a valuable metric for model performance.\n"
      ],
      "id": "31de0449"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(fpr, tpr, color=blue, lw=2, label='ROC curve')\n",
        "ax.plot([0, 1], [0, 1], color=purple, lw=2, linestyle='--', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate', color=blue)\n",
        "ax.set_ylabel('True Positive Rate', color=blue)\n",
        "ax.set_title('Receiver Operating Characteristic (ROC) Curve', color=purple)\n",
        "ax.legend(loc='lower right')\n",
        "ax.tick_params(axis='x', colors=blue)\n",
        "ax.tick_params(axis='y', colors=blue)\n",
        "ax.set_facecolor(pink)\n",
        "fig.set_facecolor(background)\n",
        "plt.show()"
      ],
      "id": "980694f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Precision-Recall (PR) Curve**\n",
        "\n",
        "PR curves focus on the trade-off between precision and recall, particularly valuable in imbalanced datasets.\n"
      ],
      "id": "0c7fa0f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(recall, precision, color=blue, lw=2, label='Precision-Recall curve')\n",
        "ax.set_xlabel('Recall (Sensitivity)', color=blue)\n",
        "ax.set_ylabel('Precision', color=blue)\n",
        "ax.set_title('Precision-Recall Curve', color=purple)\n",
        "ax.legend(loc='lower left')\n",
        "ax.tick_params(axis='x', colors=blue)\n",
        "ax.tick_params(axis='y', colors=blue)\n",
        "ax.set_facecolor(pink)\n",
        "fig.set_facecolor(background)\n",
        "plt.show()"
      ],
      "id": "b1734ef8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Confusion Matrix**\n",
        "\n",
        "The confusion matrix provides a detailed understanding of a classification model's performance, breaking down predictions into true positives, true negatives, false positives, and false negatives.\n"
      ],
      "id": "a6a9db0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "fig, ax = plt.subplots()\n",
        "cax = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.cool)\n",
        "ax.set_title('Confusion Matrix', color=purple)\n",
        "plt.colorbar(cax)\n",
        "classes = ['Class 0', 'Class 1']\n",
        "tick_marks = np.arange(len(classes))\n",
        "ax.set_xticks(tick_marks)\n",
        "ax.set_yticks(tick_marks)\n",
        "ax.set_xticklabels(classes, rotation=45, color=blue)\n",
        "ax.set_yticklabels(classes, color=blue)\n",
        "ax.set_xlabel('Predicted label', color=blue)\n",
        "ax.set_ylabel('True label', color=blue)\n",
        "fig.set_facecolor(background)\n",
        "plt.show()"
      ],
      "id": "6e2b2886",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In conclusion, classification in machine learning is a powerful tool for automating decision-making processes. By implementing and evaluating classification models, we gain insights into their performance through metrics like ROC curves, PR curves, and confusion matrices. These visualizations provide a nuanced understanding of a model's strengths and weaknesses, facilitating informed decision-making in real-world applications."
      ],
      "id": "da21d8e1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\ibhan\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}